{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Инсталляции"
      ],
      "metadata": {
        "id": "G-RuAF7OxYDk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jMjUqMwY2t_M",
        "outputId": "fac0c594-458b-46db-bd27-4096dad8b809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docxtpl\n",
            "  Downloading docxtpl-0.19.0-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting python-docx>=1.1.1 (from docxtpl)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting docxcompose (from docxtpl)\n",
            "  Downloading docxcompose-1.4.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from docxtpl) (3.1.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from docxtpl) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx>=1.1.1->docxtpl) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from docxcompose->docxtpl) (75.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from docxcompose->docxtpl) (1.16.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from docxcompose->docxtpl) (2.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->docxtpl) (3.0.2)\n",
            "Downloading docxtpl-0.19.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docxcompose\n",
            "  Building wheel for docxcompose (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docxcompose: filename=docxcompose-1.4.0-py3-none-any.whl size=23264 sha256=6db90261b5457f2c38928cdf6878c4f034b692ec8e3b25572c234d47623e6900\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/0e/78/2dc28f2d5b192d1a3ec237ec60e9d65654a078dfe07ce3a714\n",
            "Successfully built docxcompose\n",
            "Installing collected packages: python-docx, docxcompose, docxtpl\n",
            "Successfully installed docxcompose-1.4.0 docxtpl-0.19.0 python-docx-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install docxtpl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KKApHODN41yB",
        "outputId": "7d627620-0af3-4d30-9a98-44792b80859f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZW8oLZbuRg0",
        "outputId": "2cf9d9fd-dcb2-4c65-8524-6d90bc9bec6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Spire.Doc\n",
            "  Downloading Spire.Doc-12.12.0-py3-none-manylinux1_x86_64.whl.metadata (14 kB)\n",
            "Collecting plum-dispatch==1.7.4 (from Spire.Doc)\n",
            "  Downloading plum_dispatch-1.7.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading Spire.Doc-12.12.0-py3-none-manylinux1_x86_64.whl (43.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plum_dispatch-1.7.4-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: plum-dispatch, Spire.Doc\n",
            "Successfully installed Spire.Doc-12.12.0 plum-dispatch-1.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install Spire.Doc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт"
      ],
      "metadata": {
        "id": "CQRI2RQsw_Na"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ve_HXvtY3G1l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from random import shuffle, random, randint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "GWvjlXz13QGN"
      },
      "outputs": [],
      "source": [
        "# Word Documents Templating\n",
        "from docxtpl import DocxTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FRMM5aQO2irg"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UTLyGEu5yGX9"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XThFyn90BaQi"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageFilter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bHnPYKkcaVLQ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "A6_KGStnd816"
      },
      "outputs": [],
      "source": [
        "import kagglehub"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функции генерации данных"
      ],
      "metadata": {
        "id": "iOdhQBaUxRGi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "oQh4aBeQeIX_"
      },
      "outputs": [],
      "source": [
        "def get_names():\n",
        "  # Download latest version\n",
        "  path = kagglehub.dataset_download(\"rai220/russian-cyrillic-names-and-sex\")\n",
        "\n",
        "#  print(\"Path to dataset files:\", path)\n",
        "  df_names = pd.read_csv(path + '/data.csv')\n",
        "  return df_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nIdJ49EiYdwk"
      },
      "outputs": [],
      "source": [
        "def get_cities():\n",
        "  url = (\"https://raw.githubusercontent.com/\"\n",
        "        \"epogrebnyak/ru-cities/main/assets/towns.csv\")\n",
        "\n",
        "  # save file locally\n",
        "  p = Path(\"towns.csv\")\n",
        "  if not p.exists():\n",
        "      content = requests.get(url).text\n",
        "      p.write_text(content, encoding=\"utf-8\")\n",
        "\n",
        "  # read as dataframe\n",
        "  df_cities = pd.read_csv(\"towns.csv\")\n",
        "  #print(df.sample(5))\n",
        "\n",
        "  return df_cities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "zDKaqJHFTPkJ"
      },
      "outputs": [],
      "source": [
        "def get_rand_pser(n = 4):\n",
        "\n",
        "    ser = randint(1, (10**n-1))\n",
        "    nser = str(ser).rjust(n, '1')\n",
        "    return nser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "gHSeXJy4TR_y"
      },
      "outputs": [],
      "source": [
        "def get_rand_pnum(n = 6):\n",
        "\n",
        "    num = randint(0, (10**n-1))\n",
        "    pnum = str(num).rjust(n, '1')\n",
        "    return pnum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "HqpxV0CPTWAb"
      },
      "outputs": [],
      "source": [
        "def get_rand_npod(n1 = 3, n2 = 3):\n",
        "\n",
        "    num1 = randint(0, (10**n1-1))\n",
        "    num2 = randint(0, (10**n2-1))\n",
        "    pnum = str(num1).rjust(n1, '1') + '-' + str(num2).rjust(n2, '1')\n",
        "    return pnum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rAdlB0Qh5R7K"
      },
      "outputs": [],
      "source": [
        "def get_rand_date(start_date = '01.01.1940', stop_date = '01.01.2000'):\n",
        "    d1, m1, y1 = map(int, start_date.split('.'))\n",
        "    d2, m2, y2 = map(int, stop_date.split('.'))\n",
        "\n",
        "    rand_y = str(randint(y1, y2))\n",
        "    rand_m = str(randint(1, 12))\n",
        "    rand_d = str(randint(1, 28))\n",
        "    rand_date = rand_d.rjust(2, '0') + \".\" + rand_m.rjust(2, '0') + \".\" + rand_y\n",
        "\n",
        "    return rand_date"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функция генерации датфрейма с данными для N паспортов"
      ],
      "metadata": {
        "id": "HgSMfYcmxeiz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rMft_2tuSq0h"
      },
      "outputs": [],
      "source": [
        "def gen_pasp_data(n = 10):\n",
        "\n",
        "  df_cities = get_cities()\n",
        "  df_names = get_names()\n",
        "\n",
        "  #keys = ['PSER', 'PNUM', 'VYD1', 'VYD2', 'VYD3', 'DVYD', 'NPOD', 'FAM1', 'FAM2', 'NAME', 'FNAM', 'BDAT','SX', 'BPL1', 'BPL2', 'BPL3']\n",
        "  keys_descr = np.array([\n",
        "      ['PSER', 'Серия паспорта'],\n",
        "      ['PNUM', 'Номер паспорта'],\n",
        "      ['VYD1', 'Паспорт выдан (1 строка)'],\n",
        "      ['VYD2', 'Паспорт выдан (2 строка)'],\n",
        "      ['VYD3', 'Паспорт выдан (3 строка)'],\n",
        "      ['DVYD', 'Дата выдачи'],\n",
        "      ['NPOD', 'Номер подразделения'],\n",
        "      ['FAM1', 'Фамилия (1 строка)'],\n",
        "      ['FAM2', 'Фамилия (2 строка)'],\n",
        "      ['NAME', 'Имя'],\n",
        "      ['FNAM', 'Отчество'],\n",
        "      ['BDAT', 'Дата рождения'],\n",
        "      ['SX', 'Пол'],\n",
        "      ['BPL1', 'Место рождения (1 строка)'],\n",
        "      ['BPL2', 'Место рождения (2 строка)'],\n",
        "      ['BPL3', 'Место рождения (3 строка)']\n",
        "  ])\n",
        "\n",
        "  data = pd.DataFrame(columns = keys_descr[:,0])\n",
        "  data.loc[0] = keys_descr[:,1]\n",
        "\n",
        "  for i in range(n):\n",
        "\n",
        "    pser = get_rand_pser()\n",
        "    pnum = get_rand_pnum()\n",
        "    npod = get_rand_npod()\n",
        "\n",
        "    #vyd1, vyd2, vyd3 = get_rand_vyd()\n",
        "    place = df_cities.sample(1)\n",
        "    vyd1 = \"Управление МВД России\"\n",
        "    vyd2 = \"по г. \" + place.city.iloc[0] + \", \"\n",
        "    vyd3 =  place.region_name.iloc[0]\n",
        "\n",
        "    bdat = get_rand_date()\n",
        "    bd, bm , by = bdat.split('.')\n",
        "\n",
        "    dvyd = get_rand_date(start_date = \"01.01.\" + str(int(by) + 14), stop_date = \"01.01.2024\")\n",
        "\n",
        "    #fam1, fam2, name, fname, sx = get_rand_name()\n",
        "    full_name = df_names.sample(1)\n",
        "    fam1 = full_name.iloc[0,0]\n",
        "    name = full_name.iloc[0,1]\n",
        "    fnam = full_name.iloc[0,2]\n",
        "    sx = ('муж.' if full_name.iloc[0,3] == \"М\" else 'жен.')\n",
        "\n",
        "    #bpl1, bpl2, bpl3 = get_rand_bplace()\n",
        "    place = df_cities.sample(1)\n",
        "    bpl1 = \"г. \" + place.city.iloc[0] + \",\"\n",
        "    bpl2 = place.region_name.iloc[0]\n",
        "\n",
        "    data.loc[i+1] = [\n",
        "         pser,\n",
        "         pnum,\n",
        "         vyd1,\n",
        "         vyd2,\n",
        "         vyd3, #'VYD3'\n",
        "         dvyd,\n",
        "         npod,\n",
        "         fam1,\n",
        "         \"\", #'FAM2'\n",
        "         name,\n",
        "         fnam,\n",
        "         bdat,\n",
        "         sx,\n",
        "         bpl1,\n",
        "         bpl2,\n",
        "         \"\" #'BPL3'\n",
        "    ]\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функция сохранения docx в формате PNG"
      ],
      "metadata": {
        "id": "oWSZ88mFxxt5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tNuBN1hEupNV"
      },
      "outputs": [],
      "source": [
        "from spire.doc import *\n",
        "from spire.doc.common import *\n",
        "\n",
        "def print_png(path): #функция печати docx в PNG\n",
        "\n",
        "  document = Document()\n",
        "\n",
        "  # Load a Word file\n",
        "  document.LoadFromFile(path + '.docx')\n",
        "\n",
        "  # Loop through the pages in the document\n",
        "  #for i in range(document.GetPageCount()): #перебор не будем делать, печатаем только первую страницу\n",
        "    # Convert a specific page to bitmap image\n",
        "  imageStream = document.SaveImageToStreams(\n",
        "      #i,\n",
        "      0,\n",
        "      ImageType.Bitmap\n",
        "      )\n",
        "  # Save the bitmap to a PNG file\n",
        "  with open(path + '.png','wb') as imageFile:\n",
        "      imageFile.write(imageStream.ToArray())\n",
        "\n",
        "  document.Close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функции работы с PNG"
      ],
      "metadata": {
        "id": "4RiuvFe0x88X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "yACjgbgNDG7p"
      },
      "outputs": [],
      "source": [
        "def clean_passport_png(path, l = 135, u = 90, r = 660, d = 470): #функция обрезания самого паспорта\n",
        "  with Image.open(path) as img:\n",
        "    img.load()\n",
        "\n",
        "  img_clean = img.crop((l, u, r, d))\n",
        "  img_clean.save(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Db-Wqfc2blvJ"
      },
      "outputs": [],
      "source": [
        "def clean_top_png(path, h = 60): #функция обрезания верха фотографии высотой h пикселей\n",
        "  with Image.open(path) as img:\n",
        "    img.load()\n",
        "\n",
        "  img_clean = img.crop((0, h, img.width, img.height))\n",
        "  img_clean.save(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "eGqI1ohPt7nQ"
      },
      "outputs": [],
      "source": [
        "def clean_bottom_png(path, h = 430): #функция обрезания низа фотографии (ниже h пикселей)\n",
        "  with Image.open(path) as img:\n",
        "    img.load()\n",
        "\n",
        "  img_clean = img.crop((0, 0, img.width, h))\n",
        "  img_clean.save(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBN-Si6iJfZs"
      },
      "source": [
        "580 - 465, 380 - 290 - координаты места под фотографию на шаблоне"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ceYsEFIYHQQ1"
      },
      "outputs": [],
      "source": [
        "#def put_photo(pasp_path, photo_path, l = 465, u = 290, r = 580, d = 380): #Функция добавления фотографии, точки left, up, right, down (lower)\n",
        "def put_photo(pasp_path, photo_path, l = 465, u = 350, r = 580, d = 440): #Функция добавления фотографии, точки left, up, right, down (lower)\n",
        "  with Image.open(pasp_path) as pasp:\n",
        "    pasp.load()\n",
        "  with Image.open(photo_path) as photo:\n",
        "    photo.load()\n",
        "\n",
        "  photo = photo.rotate(90)\n",
        "\n",
        "  pasp.paste(\n",
        "      photo.resize(( r - l, d - u)), # уменьшаем фото\n",
        "       (l, u)\n",
        "       )\n",
        "  pasp.save(pasp_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "thDPTRB7vX1u"
      },
      "outputs": [],
      "source": [
        "def png_rand_rotate(pasp_path): #Функция поворота фотографии на случайный угол\n",
        "  with Image.open(pasp_path) as pasp:\n",
        "    pasp.load()\n",
        "\n",
        "  #angle = randint(1, 3)*90 + randint(-3, 3) #случайный угол из (0, 90, 180, 270) +-3\n",
        "  angle = 270\n",
        "  pasp = pasp.rotate(angle, expand=True, fillcolor = 1 )\n",
        "\n",
        "  pasp.save(pasp_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "4esxi0I6GInm"
      },
      "outputs": [],
      "source": [
        "def png_rand_color(pasp_path): #Функция изменения цвета\n",
        "  with Image.open(pasp_path) as pasp:\n",
        "    pasp.load()\n",
        "\n",
        "  if(randint(-1, 1) > 0):\n",
        "    pasp = pasp.convert(\"L\")\n",
        "\n",
        "  pasp.save(pasp_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "sFCn2acbnuBH"
      },
      "outputs": [],
      "source": [
        "def png_blur(pasp_path): #Функция изменения цвета\n",
        "  with Image.open(pasp_path) as pasp:\n",
        "    pasp.load()\n",
        "\n",
        "  pasp = pasp.filter(ImageFilter.GaussianBlur(1))\n",
        "\n",
        "  pasp.save(pasp_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "5tybTRmupsob"
      },
      "outputs": [],
      "source": [
        "def png_grey(pasp_path): #Функция изменения цвета\n",
        "  with Image.open(pasp_path) as pasp:\n",
        "    pasp.load()\n",
        "\n",
        "  pasp = pasp.convert(\"L\")\n",
        "\n",
        "  pasp.save(pasp_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "NP3bumAeM3C2"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "def zipdir(path, ziph):\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            ziph.write(os.path.join(root, file))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функция генерации датасета: PNG и соответствующего ему CSV"
      ],
      "metadata": {
        "id": "6AQoCkXxyMv6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "a_N3QVDbfTOS"
      },
      "outputs": [],
      "source": [
        "def make_dataset(datas):#функия генерации самого датасета (doc+json)\n",
        "  n_samples = len(datas)\n",
        "  PATH = os.getcwd()\n",
        "  date = datetime.isoformat(datetime.now()).replace('-','_')[0:10]\n",
        "\n",
        "  path_out = PATH + \"/ds_pasports_\" + date\n",
        "  path_photo = PATH + \"/photos\"\n",
        "\n",
        "  if os.path.exists(path_out) == False:\n",
        "    os.mkdir(path_out)\n",
        "\n",
        "  templates = [\"/pasp_template8_1.docx\", \"/pasp_template8_2.docx\",\"/pasp_template8_3.docx\", \"/pasp_template8_4.docx\"]\n",
        "  #templates = [\"/pasp_template7_1.docx\"]\n",
        "  photos = os.listdir(path_photo)\n",
        "\n",
        "  keys = datas.columns\n",
        "  descriptions = datas.iloc[0]\n",
        "\n",
        "  for sample_index in range(1, n_samples):\n",
        "\n",
        "    templ_index = randint(0, len(templates)-1)\n",
        "    #photo_index = randint(0, len(photos)-1)\n",
        "    photo_index = sample_index\n",
        "\n",
        "    doc = DocxTemplate(PATH + templates[templ_index])\n",
        "\n",
        "    sample = datas.loc[sample_index]\n",
        "\n",
        "    #context = {key : feature for key, feature in zip(keys, sample) }\n",
        "    context = {key.lower() : feature for key, feature in zip(keys, sample) }  #внести в код\n",
        "    context['pser'] = context['pser'][:2] + \"  \" + context['pser'][2:]        #внести в код\n",
        "    doc.render(context)\n",
        "    doc.save(f\"{path_out}/{sample_index}.docx\")\n",
        "\n",
        "    print_png(f\"{path_out}/{sample_index}\")\n",
        "    os.remove(f\"{path_out}/{sample_index}.docx\")\n",
        "\n",
        "    put_photo(f\"{path_out}/{sample_index}.png\", path_photo + '/' + photos[photo_index])\n",
        "    clean_passport_png(f\"{path_out}/{sample_index}.png\")\n",
        "    #clean_top_png(f\"{path_out}/{sample_index}.png\")\n",
        "    #clean_bottom_png(f\"{path_out}/{sample_index}.png\")\n",
        "    #png_rand_color(f\"{path_out}/{sample_index}.png\")\n",
        "    #png_grey(f\"{path_out}/{sample_index}.png\")\n",
        "    #png_blur(f\"{path_out}/{sample_index}.png\")\n",
        "    png_rand_rotate(f\"{path_out}/{sample_index}.png\")\n",
        "\n",
        "    sample_json = {descr : feature for descr, feature in zip(descriptions, sample) }\n",
        "    sample_json['Класс документа'] = \"Паспорт\"\n",
        "    sample_json['Страна'] = \"Российская Федерация\"\n",
        "    sample_json['Печать'] = \"CV макет Test\"\n",
        "    json_to_file = json.dumps(sample_json, indent=4, ensure_ascii=False)\n",
        "\n",
        "    # Writing to sample.json\n",
        "    with open(f\"{path_out}/{sample_index}.json\", \"w\") as outfile:\n",
        "        outfile.write(json_to_file)\n",
        "\n",
        "\n",
        "  zip_filename = str(n_samples - 1) + 'sampl_dataset_pasports_' + date + \".zip\"\n",
        "  zipf = zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED)\n",
        "  zipdir(path_out, zipf)\n",
        "  zipf.close()\n",
        "\n",
        "  files_to_del = os.listdir(path_out)\n",
        "  for ftd in files_to_del:\n",
        "    os.remove(path_out + \"/\" + ftd)\n",
        "\n",
        "  os.rmdir(path_out)\n",
        "\n",
        "  datas.to_csv(\"/content/data.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main()"
      ],
      "metadata": {
        "id": "7i-H85UiyYhi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSZUCu_dl8K8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48157d83-3995-4c0f-b08d-4e7f7ad876f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rai220/russian-cyrillic-names-and-sex?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55.1M/55.1M [00:03<00:00, 14.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "rand_pasp_data = gen_pasp_data(n = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW-fhxo_RyrA"
      },
      "outputs": [],
      "source": [
        "make_dataset(rand_pasp_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Эта часть для генерации вопросника"
      ],
      "metadata": {
        "id": "EBdUVH-nk0fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_QA(datas: pd.DataFrame): #функция создания вопросника (дата в путь вписана вручную)\n",
        "  datas.fillna(\"\", inplace = True)\n",
        "  datas_to_QA = datas.drop(columns = ['PSER','VYD2', 'VYD3', 'FAM2', 'BPL2', 'BPL3'])\n",
        "\n",
        "  datas_to_QA['VYD1'] = datas['VYD1'] + \" \" + datas['VYD2'] + \" \" + datas['VYD3']\n",
        "  datas_to_QA['BPL1'] = datas['BPL1'] + \" \" + datas['BPL2'] + \" \" + datas['BPL3']\n",
        "  datas_to_QA['FAM1'] = datas['FAM1'] + \" \" + datas['FAM2']\n",
        "  datas_to_QA['PNUM'] = datas['PSER'] + \" \" + datas['PNUM']\n",
        "\n",
        "  datas_to_QA.iloc[0] = ['Серия и номер паспорта','Паспорт выдан','Дата выдачи','Номер подразделения','Фамилия','Имя','Отчество', 'Дата рождения','Пол','Место рождения']\n",
        "\n",
        "\n",
        "  testQA_columns = ['data_index','question', 'answer', 'doc class', 'question type', 'answer bbox','split', 'image_path']\n",
        "  testQA = []\n",
        "\n",
        "  for sample_index in range(1, len(datas_to_QA)):\n",
        "    for qw, anw in zip(datas_to_QA.iloc[0], datas_to_QA.iloc[sample_index]):\n",
        "      testQA.append([sample_index, \"Напиши \" + qw, anw, 'Паспорт РФ', qw, \"\", 'test_clean', \"\\content\\ds_pasports_2024_12_07\\\\\" + str(sample_index) + '.png'])\n",
        "\n",
        "  testQA = pd.DataFrame(testQA, columns = testQA_columns)\n",
        "  testQA.to_csv(\"/content/10_samples_qwa.csv\", sep=\";\", encoding=\"utf-8-sig\", index=False)\n",
        "\n",
        "  return testQA"
      ],
      "metadata": {
        "id": "lE8CFnmruvQz"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "datas = pd.read_csv(\"/content/data (3).csv\", index_col=0)\n",
        "testQA = get_QA(datas)\n",
        "make_dataset(datas)\n",
        "datas.to_csv(\"/content/data.csv\", sep=\";\", encoding=\"utf-8-sig\", index=False)"
      ],
      "metadata": {
        "id": "wO5TqUediYLE"
      },
      "execution_count": 2,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "G-RuAF7OxYDk",
        "CQRI2RQsw_Na",
        "iOdhQBaUxRGi",
        "HgSMfYcmxeiz",
        "oWSZ88mFxxt5",
        "4RiuvFe0x88X",
        "6AQoCkXxyMv6",
        "7i-H85UiyYhi",
        "EBdUVH-nk0fc"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}